# -*- coding: utf-8 -*-
"""new_xgboost.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yHaGBtB07tg8q5Von74LIv756-nbIMrM
"""

!pip install numpy==1.16.1

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd drive/
# %cd My\ Drive
# %cd Animal_Detection_Dataset

import cv2
#import numpy as np
import pkg_resources
#pkg_resources.require("numpy==`1.16.2")  # modified to use specific numpy
import numpy as np
from tqdm import tqdm
import os
from random import shuffle
from time import time
# tensorboard --logdir=logs/ --host localhost --port 8088
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score
import pandas as pd

TRAIN_DIR = 'Train'
TEST_DIR = 'Test'
SINGLE_DIR = 'single_prediction'
EXTRA_DIR = 'extra_images'
IMG_SIZE = 50
BATCH_SIZE = 32

SPECIES = ['coati', 'roe_deer', 'wild_boar']

for species in SPECIES:
    print('{} {} images'.format(species, len(os.listdir(os.path.join(TRAIN_DIR, species)))))

trainn = []

for species_num, species in enumerate(SPECIES):
    for file in os.listdir(os.path.join(TRAIN_DIR, species)):
        trainn.append(['Train/{}/{}'.format(species, file), species_num, species])

trainn = pd.DataFrame(trainn, columns=['file', 'species_num', 'species'])

print('Training Data: ',trainn.shape)
print(trainn)

testt = []

for species_num, species in enumerate(SPECIES):
    for file in os.listdir(os.path.join(TEST_DIR, species)):
        testt.append(['Test/{}/{}'.format(species, file), species_num, species])

testt = pd.DataFrame(testt, columns=['file', 'species_num', 'species'])

print('Testing Data: ',testt.shape)
print(testt)

def get_model(saved=True):
    model = XGBClassifier()
    return model

def get_training_data():
    """Returns the training data from TRAIN_DIR.
    Images are read in grayscale format and resized to IMG_SIZE dimension square.
    The whole data is saved with numpy in .npy format for quick loading for future purpose.
    """
    training_data = []
    if os.path.isfile('training_data_{}.npy'.format(IMG_SIZE)):
        return np.load('training_data_{}.npy'.format(IMG_SIZE))
    else:
        for species in SPECIES:
          for img in tqdm(os.listdir(os.path.join(TRAIN_DIR, species))):
              label = species
              path = os.path.join(os.path.join(TRAIN_DIR, species) ,img)
              print(path)
              img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))
              img = img/255
              training_data.append([np.array(img),np.array(label)])
        shuffle(training_data)
        np.save('training_data_{}.npy'.format(IMG_SIZE),training_data)
        return np.array(training_data)

def get_testing_data():
    """Returns the testing data from TEST_DIR.
    Images are read in grayscale format and resized to IMG_SIZE dimension square.
    The whole data is saved with numpy in .npy format for quick loading for future purpose.
    """
    testing_data = []
    if os.path.isfile('testing_data_{}.npy'.format(IMG_SIZE)):
        return np.load('testing_data_{}.npy'.format(IMG_SIZE))
    else:
        for species in SPECIES:
          for img in tqdm(os.listdir(os.path.join(TEST_DIR, species))):
              label = species
              path = os.path.join(os.path.join(TEST_DIR, species) ,img)
              print(path)
              img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))
              img = img/255
              testing_data.append([np.array(img),np.array(label)])
        shuffle(testing_data)
        np.save('testing_data_{}.npy'.format(IMG_SIZE),testing_data)
        return np.array(testing_data)

def get_single_data():
    """Returns the testing data from TEST_DIR.
    Images are read in grayscale format and resized to IMG_SIZE dimension square.
    The whole data is saved with numpy in .npy format for quick loading for future purpose.
    """
    single_data = []
    if os.path.isfile('single_data_{}.npy'.format(IMG_SIZE)):
        return np.load('single_data_{}.npy'.format(IMG_SIZE))
    else:
        for img in tqdm(os.listdir(SINGLE_DIR)):
            #img_id = int(img.split('.')[0])
            path = os.path.join(SINGLE_DIR,img)
            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))
            img = img/255
            single_data.append([np.array(img),"anything"])
        single_data.sort(key = lambda x: x[1])
        np.save('single_data_{}.npy'.format(IMG_SIZE),single_data)
        return np.array(single_data)

#!pip install numpy==1.16.1
import numpy as np

data = get_training_data()
print(data.shape)

partition = 1500            # Breaking -ve index
train = data[:partition]    #  For Training purpose
# Training set
X_train = np.array([i[0] for i in train])#.reshape((1,-1))
y_train = np.array([i[1] for i in train])
X_train = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE*IMG_SIZE)/255.
print(X_train.shape)
print(y_train.shape)

#Validation Data

test_data = get_testing_data()
print(test_data.shape)

# Validation set
partition = 150            # Breaking -ve index
test = test_data[:partition]
X_val = np.array([i[0] for i in test])
X_val = np.array([i[0] for i in test]).reshape(-1,IMG_SIZE*IMG_SIZE)/255. #.reshape((1, -1))
y_val = np.array([i[1] for i in test])
print(X_val.shape)
print(y_val.shape)

model = get_model()

eval_set = [(X_val, y_val)]
model.fit(X_train,y_train, early_stopping_rounds=10, eval_metric="mlogloss", eval_set=eval_set, verbose=True)

'''
import pickle
# Save the trained model as a pickle string.
saved_model = pickle.dumps(model)
# Load the pickled model
saved_model = pickle.loads(saved_model)


'''

y_pred_train = model.predict(X_train)
accuracy = accuracy_score(y_train, y_pred_train)
print("Accuracy:%.2f%%"%(accuracy * 100.0))

y_pred = model.predict(X_val)
#print(y_pred)
accuracy = accuracy_score(y_val, y_pred)
#print(y_val)
print("Accuracy:%.2f%%"%(accuracy * 100.0))

#Prediction on Single Data
single_data = get_single_data()

X_single = np.array([i[0] for i in single_data]).reshape(-1,IMG_SIZE*IMG_SIZE)/255.
#ids = [i[1] for i in single_data]
pred = model.predict(X_single)
print(pred)

import cv2
bb_model = 'MobileNetSSD_deploy.caffemodel'
prototxt = 'MobileNetSSD_deploy.prototxt.txt'
# image = 'images/example_05.jpg'
c_confidence = .5

# initialize the list of class labels MobileNet SSD was trained to
# detect, then generate a set of bounding box colors for each class

CLASSES = ["background", "aeroplane", "bicycle", "bird", "boat",
	"bottle", "bus", "car", "cat", "chair", "cow", "diningtable",
	"dog", "horse", "motorbike", "person", "pottedplant", "sheep",
	"sofa", "train", "tvmonitor"]

COLORS = np.random.uniform(0, 255, size=(len(CLASSES), 3))

# load our serialized model from disk
# print("[INFO] loading model...")
net = cv2.dnn.readNetFromCaffe(prototxt, bb_model)

# Commented out IPython magic to ensure Python compatibility.
# %cd single_prediction/
from google.colab.patches import cv2_imshow
image = 'deer.JPG'
image = cv2.imread(image)
(h, w) = image.shape[:2]
blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)

# pass the blob through the network and obtain the detections and
# predictions
# print("[INFO] computing object detections...")
net.setInput(blob)
detections = net.forward()

# loop over the detections
for i in np.arange(0, detections.shape[2]):
	# extract the confidence (i.e., probability) associated with the
	# prediction
	confidence = detections[0, 0, i, 2]

	# filter out weak detections by ensuring the `confidence` is
	# greater than the minimum confidence
	if confidence > c_confidence:
		# extract the index of the class label from the `detections`,
		# then compute the (x, y)-coordinates of the bounding box for
		# the object
		idx = int(detections[0, 0, i, 1])
		box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
		(startX, startY, endX, endY) = box.astype("int")

		# display the prediction
		#label = "{}: {:.2f}%".format(CLASSES[idx], confidence * 100)
		label = pred[0]
    #print("[INFO] {}".format(label))
		cv2.rectangle(image, (startX, startY), (endX, endY),
			COLORS[idx], 2)
		y = startY - 15 if startY - 15 > 15 else startY + 15
		cv2.putText(image, label, (startX, y),
				cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)

# show the output image
cv2_imshow(image)
cv2.waitKey(0)

from google.colab.patches import cv2_imshow
image = 'boar.JPG'
image = cv2.imread(image)
(h, w) = image.shape[:2]
blob = cv2.dnn.blobFromImage(cv2.resize(image, (300, 300)), 0.007843, (300, 300), 127.5)

# pass the blob through the network and obtain the detections and
# predictions
# print("[INFO] computing object detections...")
net.setInput(blob)
detections = net.forward()

# loop over the detections
for i in np.arange(0, detections.shape[2]):
	# extract the confidence (i.e., probability) associated with the
	# prediction
	confidence = detections[0, 0, i, 2]

	# filter out weak detections by ensuring the `confidence` is
	# greater than the minimum confidence
	if confidence > c_confidence:
		# extract the index of the class label from the `detections`,
		# then compute the (x, y)-coordinates of the bounding box for
		# the object
		idx = int(detections[0, 0, i, 1])
		box = detections[0, 0, i, 3:7] * np.array([w, h, w, h])
		(startX, startY, endX, endY) = box.astype("int")

		# display the prediction
		#label = "{}: {:.2f}%".format(CLASSES[idx], confidence * 100)
		label = pred[1]
    #print("[INFO] {}".format(label))
		cv2.rectangle(image, (startX, startY), (endX, endY),
			COLORS[idx], 2)
		y = startY - 15 if startY - 15 > 15 else startY + 15
		cv2.putText(image, label, (startX, y),
				cv2.FONT_HERSHEY_SIMPLEX, 0.5, COLORS[idx], 2)

# show the output image
cv2_imshow(image)
cv2.waitKey(0)

"""EXTRA DATA TESTING"""

# Commented out IPython magic to ensure Python compatibility.
# %cd ..



def get_extra_data():
    """Returns the testing data from TEST_DIR.
    Images are read in grayscale format and resized to IMG_SIZE dimension square.
    The whole data is saved with numpy in .npy format for quick loading for future purpose.
    """
    extra_data = []
    if os.path.isfile('extra_data_{}.npy'.format(IMG_SIZE)):
        return np.load('extra_data_{}.npy'.format(IMG_SIZE))
    else:
        for img in tqdm(os.listdir(EXTRA_DIR)):
            #img_id = int(img.split('.')[0])
            path = os.path.join(EXTRA_DIR,img)
            img = cv2.resize(cv2.imread(path,cv2.IMREAD_GRAYSCALE), (IMG_SIZE,IMG_SIZE))
            img = img/255
            extra_data.append([np.array(img),"anything"])
        extra_data.sort(key = lambda x: x[1])
        np.save('extra_data_{}.npy'.format(IMG_SIZE),extra_data)
        return np.array(extra_data)

model

#Prediction on Extra Data
extra_data = get_extra_data()
X_extra = np.array([i[0] for i in extra_data]).reshape(-1,IMG_SIZE*IMG_SIZE)/255.
#ids = [i[1] for i in single_data]
pred = model.predict(X_extra)
print(pred)

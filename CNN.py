# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rGLGXiZxDNQbeGbI4-JmThIRMGmXjZp7
"""

# Commented out IPython magic to ensure Python compatibility.
'''
a = []
while(1):
  a.append('1')
'''
# %tensorflow_version 1.15.0

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd drive/
# %cd My\ Drive
# %cd Animal_Detection_Dataset



import os
import pandas as pd

TRAIN_DIR = 'Train'
TEST_DIR = 'Test'
SINGLE_DIR = 'single-pred'
IMG_SIZE = 50
BATCH_SIZE = 32

#!ls
SPECIES = ['coati', 'roe_deer', 'wild_boar']

for species in SPECIES:
    print('{} {} images'.format(species, len(os.listdir(os.path.join(TRAIN_DIR, species)))))

trainn = []

for species_num, species in enumerate(SPECIES):
    for file in os.listdir(os.path.join(TRAIN_DIR, species)):
        trainn.append(['Train/{}/{}'.format(species, file), species_num, species])

trainn = pd.DataFrame(trainn, columns=['file', 'species_num', 'species'])

print('Training Data: ',trainn.shape)
print(trainn)

testt = []

for species_num, species in enumerate(SPECIES):
    for file in os.listdir(os.path.join(TEST_DIR, species)):
        testt.append(['Test/{}/{}'.format(species, file), species_num, species])

testt = pd.DataFrame(testt, columns=['file', 'species_num', 'species'])

print('Testing Data: ',testt.shape)
print(testt)

#Importing the Keras Libraries and packages
from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint

# Initializing the CNN
classifier = Sequential()

#Step 1 - Convolution
classifier.add(Convolution2D(32, 3, 3, input_shape=(50, 50, 3), activation = 'relu'))

#Step 2 - Pooling
classifier.add(MaxPooling2D(pool_size= (2, 2)))

# To increase Efficiency, add another Convolutional layer
classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))
classifier.add(MaxPooling2D(pool_size= (2, 2)))

#Step 3 - Flattening
classifier.add(Flatten())

#Step 4 - Full Connection
classifier.add(Dense(output_dim = 128, activation = 'relu'))
#Output layer
classifier.add(Dense(output_dim = 3, activation = 'softmax'))

#Compiling the CNN
classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])

# Part 2 : Fitting the CNN to the images
from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
        rescale=1./255,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True)

test_datagen = ImageDataGenerator(rescale=1./255)

training_set = train_datagen.flow_from_directory('Train',
                                                 target_size=(50, 50),
                                                 batch_size=5,
                                                 class_mode='categorical')


test_set = test_datagen.flow_from_directory('Test',
                                            target_size=(50, 50),
                                            batch_size=5,
                                            class_mode='categorical')

print(test_set)

# simple early stopping
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=150)
mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)

# fit model
#history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es, mc])
history = classifier.fit(training_set,steps_per_epoch=(210/5),epochs=150,validation_data=test_set,validation_steps=(90/5), verbose=1, callbacks=[es, mc])
